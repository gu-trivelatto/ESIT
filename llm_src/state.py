from typing import List, Dict
from typing_extensions import TypedDict

### State

class GraphState(TypedDict):
    """
    Represents the state of the graph.

    Attributes:
        num_steps: number of steps already taken
        history: a list containing the history of user inputs and model outputs
        user_input: user input provided to the pipeline
        consolidated_input: user input + necessary context if it references past iterations
        input_type: 'mixed', 'general' or 'energy_system', defines the branch to be run
        query_history: list of queries already fed to the 'general' tools
        next_query: next query generated for the 'general' tools, contains the query and the selected tool
        context: list of context gathered from the tools
        is_data_complete: boolean to indicate that all necessary context was gathered
        action_history: list of actions already taken by the 'energy_system' branch
        next_action: next action to be taken by the 'energy_system' tools
        retrieval_type: type of info retrieval to use ('paper' or 'model')
        model_info: list with all information gathered from the model
        scen_modded: the scenario was already modified by the 'energy_system' branch
        final_answer: final answer generated by the LLM, the one to be displayed to the user
    """
    num_steps: int
    history: List[dict]
    user_input: str
    consolidated_input: str
    input_type: str
    query_history: List[str]
    next_query: dict
    context: List[str]
    is_data_complete: bool
    action_history: List[str]
    next_action: str
    retrieval_type: str
    model_info: List[str]
    scen_modded: bool
    final_answer: str
    
    @staticmethod
    def initialize(user_input: str, history: List[dict]) -> 'GraphState':
        return GraphState(
            num_steps=0,
            history=history,
            user_input=user_input,
            consolidated_input="",
            input_type="",
            selected_tool="",
            query_history=[],
            next_query={},
            context=[],
            is_data_complete=False,
            action_history=[],
            next_action="",
            retrieval_type="",
            model_info=[],
            scen_modded=False,
            final_answer=""
        )
    
    
    
    
    
    
    
    
    
    
    
    
    
    